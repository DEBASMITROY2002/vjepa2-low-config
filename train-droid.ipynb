{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021ef26b",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c23150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from src.utils.my_logger import get_colorlogger\n",
    "from src.utils.logging import AverageMeter, CSVLogger, get_logger, gpu_timer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31fe2c",
   "metadata": {},
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5899ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_colorlogger(name=\"train-droid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3024ade",
   "metadata": {},
   "source": [
    "## Loading configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2431504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:02\u001b[0m train-droid \u001b[1;35m1880302584.py:5\u001b[0m loaded params...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_fname = \"mydroiddata/droid-256px-8f.yaml\"\n",
    "\n",
    "with open(config_fname, \"r\") as y_file:\n",
    "        args = yaml.load(y_file, Loader=yaml.FullLoader)\n",
    "        logger.info(\"loaded params...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f783b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_GLOBAL_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a0ee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:03\u001b[0m train-droid \u001b[1;35m1516709990.py:16\u001b[0m which_dtype='bfloat16'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# -- META\n",
    "folder = args.get(\"folder\")\n",
    "cfgs_meta = args.get(\"meta\")\n",
    "r_file = cfgs_meta.get(\"resume_checkpoint\", None)\n",
    "p_file = cfgs_meta.get(\"pretrain_checkpoint\", None)\n",
    "load_predictor = cfgs_meta.get(\"load_predictor\", False)\n",
    "context_encoder_key = cfgs_meta.get(\"context_encoder_key\", \"encoder\")\n",
    "target_encoder_key = cfgs_meta.get(\"target_encoder_key\", \"target_encoder\")\n",
    "load_encoder = cfgs_meta.get(\"load_encoder\", True)\n",
    "seed = cfgs_meta.get(\"seed\", _GLOBAL_SEED)\n",
    "save_every_freq = cfgs_meta.get(\"save_every_freq\", -1)\n",
    "skip_batches = cfgs_meta.get(\"skip_batches\", -1)\n",
    "use_sdpa = cfgs_meta.get(\"use_sdpa\", False)\n",
    "sync_gc = cfgs_meta.get(\"sync_gc\", False)\n",
    "which_dtype = cfgs_meta.get(\"dtype\")\n",
    "logger.info(f\"{which_dtype=}\")\n",
    "if which_dtype.lower() == \"bfloat16\":\n",
    "    dtype = torch.bfloat16\n",
    "    mixed_precision = True\n",
    "elif which_dtype.lower() == \"float16\":\n",
    "    dtype = torch.float16\n",
    "    mixed_precision = True\n",
    "else:\n",
    "    dtype = torch.float32\n",
    "    mixed_precision = False\n",
    "\n",
    "# -- MODEL\n",
    "cfgs_model = args.get(\"model\")\n",
    "compile_model = cfgs_model.get(\"compile_model\", False)\n",
    "use_activation_checkpointing = cfgs_model.get(\"use_activation_checkpointing\", False)\n",
    "model_name = cfgs_model.get(\"model_name\")\n",
    "pred_depth = cfgs_model.get(\"pred_depth\")\n",
    "pred_num_heads = cfgs_model.get(\"pred_num_heads\", None)\n",
    "pred_embed_dim = cfgs_model.get(\"pred_embed_dim\")\n",
    "pred_is_frame_causal = cfgs_model.get(\"pred_is_frame_causal\", True)\n",
    "uniform_power = cfgs_model.get(\"uniform_power\", False)\n",
    "use_rope = cfgs_model.get(\"use_rope\", False)\n",
    "use_silu = cfgs_model.get(\"use_silu\", False)\n",
    "use_pred_silu = cfgs_model.get(\"use_pred_silu\", False)\n",
    "wide_silu = cfgs_model.get(\"wide_silu\", True)\n",
    "use_extrinsics = cfgs_model.get(\"use_extrinsics\", False)\n",
    "\n",
    "# -- DATA\n",
    "cfgs_data = args.get(\"data\")\n",
    "datasets = cfgs_data.get(\"datasets\", [])\n",
    "dataset_path = datasets[0]\n",
    "dataset_fpcs = cfgs_data.get(\"dataset_fpcs\")\n",
    "max_num_frames = max(dataset_fpcs)\n",
    "camera_frame = cfgs_data.get(\"camera_frame\", False)\n",
    "camera_views = cfgs_data.get(\"camera_views\", [\"left_mp4_path\"])\n",
    "stereo_view = cfgs_data.get(\"stereo_view\", False)\n",
    "batch_size = cfgs_data.get(\"batch_size\")\n",
    "tubelet_size = cfgs_data.get(\"tubelet_size\")\n",
    "fps = cfgs_data.get(\"fps\")\n",
    "crop_size = cfgs_data.get(\"crop_size\", 256)\n",
    "patch_size = cfgs_data.get(\"patch_size\")\n",
    "pin_mem = cfgs_data.get(\"pin_mem\", False)\n",
    "num_workers = cfgs_data.get(\"num_workers\", 1)\n",
    "persistent_workers = cfgs_data.get(\"persistent_workers\", True)\n",
    "\n",
    "# -- DATA AUGS\n",
    "cfgs_data_aug = args.get(\"data_aug\")\n",
    "horizontal_flip = cfgs_data_aug.get(\"horizontal_flip\", False)\n",
    "ar_range = cfgs_data_aug.get(\"random_resize_aspect_ratio\", [3 / 4, 4 / 3])\n",
    "rr_scale = cfgs_data_aug.get(\"random_resize_scale\", [0.3, 1.0])\n",
    "motion_shift = cfgs_data_aug.get(\"motion_shift\", False)\n",
    "reprob = cfgs_data_aug.get(\"reprob\", 0.0)\n",
    "use_aa = cfgs_data_aug.get(\"auto_augment\", False)\n",
    "\n",
    "# -- LOSS\n",
    "cfgs_loss = args.get(\"loss\")\n",
    "loss_exp = cfgs_loss.get(\"loss_exp\")\n",
    "normalize_reps = cfgs_loss.get(\"normalize_reps\")\n",
    "auto_steps = min(cfgs_loss.get(\"auto_steps\", 1), max_num_frames)\n",
    "# --\n",
    "tokens_per_frame = int((crop_size // patch_size) ** 2)\n",
    "\n",
    "# -- OPTIMIZATION\n",
    "cfgs_opt = args.get(\"optimization\")\n",
    "ipe = cfgs_opt.get(\"ipe\", None)\n",
    "wd = float(cfgs_opt.get(\"weight_decay\"))\n",
    "final_wd = float(cfgs_opt.get(\"final_weight_decay\"))\n",
    "num_epochs = cfgs_opt.get(\"epochs\")\n",
    "anneal = cfgs_opt.get(\"anneal\")\n",
    "warmup = cfgs_opt.get(\"warmup\")\n",
    "start_lr = cfgs_opt.get(\"start_lr\")\n",
    "lr = cfgs_opt.get(\"lr\")\n",
    "final_lr = cfgs_opt.get(\"final_lr\")\n",
    "enc_lr_scale = cfgs_opt.get(\"enc_lr_scale\", 1.0)\n",
    "betas = cfgs_opt.get(\"betas\", (0.9, 0.999))\n",
    "eps = cfgs_opt.get(\"eps\", 1.0e-8)\n",
    "# ----------------------------------------------------------------------- #\n",
    "# ----------------------------------------------------------------------- #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bad135",
   "metadata": {},
   "source": [
    "## Setting Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf880df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:04\u001b[0m train-droid \u001b[1;35m3734729410.py:5\u001b[0m Using Apple GPU\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load apple gpu\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    logger.info(\"Using Apple GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f777cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size, rank = 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ed3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # -- log/checkpointing paths\n",
    "log_file = os.path.join(folder, f\"log_r{rank}.csv\")\n",
    "latest_path = os.path.join(folder, \"latest.pt\")\n",
    "resume_path = os.path.join(folder, r_file) if r_file is not None else latest_path\n",
    "if not os.path.exists(resume_path):\n",
    "    resume_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bb618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- make csv_logger\n",
    "csv_logger = CSVLogger(\n",
    "    log_file,\n",
    "    (\"%d\", \"epoch\"),\n",
    "    (\"%d\", \"itr\"),\n",
    "    (\"%.5f\", \"loss\"),\n",
    "    (\"%d\", \"iter-time(ms)\"),\n",
    "    (\"%d\", \"gpu-time(ms)\"),\n",
    "    (\"%d\", \"dataload-time(ms)\"),\n",
    "    mode=\"+a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe00aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app: vjepa_droid\n",
      "cpus_per_task: 4\n",
      "folder: mydroiddata/droid-256px-8f\n",
      "mem_per_gpu: 22G\n",
      "nodes: 1\n",
      "tasks_per_node: 1\n",
      "data:\n",
      "    batch_size: 1\n",
      "    camera_views: ['left_mp4_path']\n",
      "    crop_size: 224\n",
      "    datasets: ['mydroiddata/dataset/droid_raw/droid_index.csv']\n",
      "    dataset_fpcs: [8]\n",
      "    fps: 3\n",
      "    num_workers: 0\n",
      "    patch_size: 16\n",
      "    pin_mem: True\n",
      "    stereo_view: False\n",
      "    tubelet_size: 2\n",
      "data_aug:\n",
      "    auto_augment: False\n",
      "    horizontal_flip: False\n",
      "    motion_shift: False\n",
      "    random_resize_aspect_ratio: [0.85, 1.15]\n",
      "    random_resize_scale: [0.8, 1.0]\n",
      "    reprob: 0.0\n",
      "loss:\n",
      "    auto_steps: 2\n",
      "    loss_exp: 1.0\n",
      "    normalize_reps: True\n",
      "    reg_coeff: 0.0\n",
      "meta:\n",
      "    dtype: bfloat16\n",
      "    eval_freq: 50\n",
      "    resume_checkpoint: None\n",
      "    load_predictor: False\n",
      "    pretrain_checkpoint: mydroiddata/droid-256px-8f/checkpoints/vitl.pt\n",
      "    context_encoder_key: target_encoder\n",
      "    target_encoder_key: target_encoder\n",
      "    save_every_freq: 10\n",
      "    seed: 239\n",
      "    use_sdpa: True\n",
      "model:\n",
      "    model_name: vit_large\n",
      "    pred_depth: 12\n",
      "    pred_embed_dim: 1024\n",
      "    pred_is_frame_causal: True\n",
      "    pred_num_heads: 16\n",
      "    uniform_power: True\n",
      "    use_activation_checkpointing: True\n",
      "    use_extrinsics: False\n",
      "    use_rope: True\n",
      "optimization:\n",
      "    anneal: 10\n",
      "    epochs: 30\n",
      "    final_lr: 1e-06\n",
      "    final_weight_decay: 0.04\n",
      "    ipe: 300\n",
      "    lr: 0.0001\n",
      "    start_lr: 1e-05\n",
      "    warmup: 5\n",
      "    weight_decay: 0.04\n",
      "log_file: mydroiddata/droid-256px-8f/log_r0.csv\n",
      "latest_path: mydroiddata/droid-256px-8f/latest.pt\n",
      "resume_path: None\n"
     ]
    }
   ],
   "source": [
    "# Print the vars\n",
    "for k, v in args.items():\n",
    "    if isinstance(v, dict):\n",
    "        print(f\"{k}:\")\n",
    "        for k1, v1 in v.items():\n",
    "            print(f\"    {k1}: {v1}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"log_file:\", log_file)\n",
    "print(\"latest_path:\", latest_path)\n",
    "print(\"resume_path:\", resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18d45e",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35aa940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debasmitroy/Desktop/programming/research/vjepa2-low-config/.venv/lib/python3.13/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from app.vjepa_droid.utils import (\n",
    "    init_opt, \n",
    "    init_video_model, \n",
    "    load_checkpoint, \n",
    "    load_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1757f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c1ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"vit_large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af09cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m train-droid \u001b[1;35mutils.py:190\u001b[0m VisionTransformer(\n",
      "  (patch_embed): PatchEmbed3D(\n",
      "    (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-23): 24 x Block(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): RoPEAttention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      ")\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m train-droid \u001b[1;35mutils.py:191\u001b[0m VisionTransformerPredictorAC(\n",
      "  (predictor_embed): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (action_encoder): Linear(in_features=7, out_features=1024, bias=True)\n",
      "  (state_encoder): Linear(in_features=7, out_features=1024, bias=True)\n",
      "  (extrinsics_encoder): Linear(in_features=6, out_features=1024, bias=True)\n",
      "  (predictor_blocks): ModuleList(\n",
      "    (0-11): 12 x ACBlock(\n",
      "      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): ACRoPEAttention(\n",
      "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  (predictor_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      ")\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m train-droid \u001b[1;35mutils.py:196\u001b[0m Encoder number of parameters: 303885312\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m train-droid \u001b[1;35mutils.py:197\u001b[0m Predictor number of parameters: 153279488\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# -- init model\n",
    "encoder, predictor = init_video_model(\n",
    "    uniform_power=uniform_power,\n",
    "    device=device,\n",
    "    patch_size=patch_size,\n",
    "    max_num_frames=512,\n",
    "    tubelet_size=tubelet_size,\n",
    "    model_name=model_name,\n",
    "    crop_size=crop_size,\n",
    "    pred_depth=pred_depth,\n",
    "    pred_num_heads=pred_num_heads,\n",
    "    pred_embed_dim=pred_embed_dim,\n",
    "    action_embed_dim=7,\n",
    "    pred_is_frame_causal=pred_is_frame_causal,\n",
    "    use_extrinsics=use_extrinsics,\n",
    "    use_sdpa=use_sdpa,\n",
    "    use_silu=use_silu,\n",
    "    use_pred_silu=use_pred_silu,\n",
    "    wide_silu=wide_silu,\n",
    "    use_rope=use_rope,\n",
    "    use_activation_checkpointing=use_activation_checkpointing,\n",
    ")\n",
    "target_encoder = copy.deepcopy(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4662302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000838210962957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "151968128/303885312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7cd9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compile_model:\n",
    "        logger.info(\"Compiling encoder, target_encoder, and predictor.\")\n",
    "        torch._dynamo.config.optimize_ddp = False\n",
    "        encoder.compile()\n",
    "        target_encoder.compile()\n",
    "        predictor.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b6eb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L \\\n",
    "#   https://dl.fbaipublicfiles.com/vjepa2/vitl.pt \\\n",
    "#   -o mydroiddata/droid-256px-8f/checkpoints/vitl.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf9c910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m train-droid \u001b[1;35mutils.py:35\u001b[0m Loading pretrained model from mydroiddata/droid-256px-8f/checkpoints/vitl.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:21\u001b[0m checkpoint-loader \u001b[1;35mcheckpoint_loader.py:30\u001b[0m Loading checkpoint from mydroiddata/droid-256px-8f/checkpoints/vitl.pt, attempt 1/3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained encoder keys: ['patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:23\u001b[0m train-droid \u001b[1;35mutils.py:47\u001b[0m loaded pretrained encoder from epoch 40 with msg: <All keys matched successfully>\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:03:24\u001b[0m train-droid \u001b[1;35mutils.py:63\u001b[0m loaded pretrained target encoder from epoch 40 with msg: <All keys matched successfully>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']\n"
     ]
    }
   ],
   "source": [
    "# -- looad pretrained weights\n",
    "encoder, predictor, target_encoder = load_pretrained(\n",
    "    r_path=p_file,\n",
    "    encoder=encoder,\n",
    "    predictor=predictor,\n",
    "    context_encoder_key=context_encoder_key,\n",
    "    target_encoder_key=target_encoder_key,\n",
    "    target_encoder=target_encoder,\n",
    "    load_predictor=load_predictor,\n",
    "    load_encoder=load_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f970acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mydroiddata/droid-256px-8f/checkpoints/vitl.pt'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29df8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in target_encoder.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c07a458e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34m2026-01-04 13:00:10\u001b[0m checkpoint-loader \u001b[1;35mcheckpoint_loader.py:30\u001b[0m Loading checkpoint from mydroiddata/droid-256px-8f/checkpoints/vitl.pt, attempt 1/3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.utils.checkpoint_loader import robust_checkpoint_loader\n",
    "checkpoint = robust_checkpoint_loader(p_file, map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ed189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = checkpoint[context_encoder_key]\n",
    "pretrained_dict_ = {k.replace(\"module.backbone.\", \"\"): v for k, v in pretrained_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdfa1c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'blocks.12.norm1.weight', 'blocks.12.norm1.bias', 'blocks.12.attn.qkv.weight', 'blocks.12.attn.qkv.bias', 'blocks.12.attn.proj.weight', 'blocks.12.attn.proj.bias', 'blocks.12.norm2.weight', 'blocks.12.norm2.bias', 'blocks.12.mlp.fc1.weight', 'blocks.12.mlp.fc1.bias', 'blocks.12.mlp.fc2.weight', 'blocks.12.mlp.fc2.bias', 'blocks.13.norm1.weight', 'blocks.13.norm1.bias', 'blocks.13.attn.qkv.weight', 'blocks.13.attn.qkv.bias', 'blocks.13.attn.proj.weight', 'blocks.13.attn.proj.bias', 'blocks.13.norm2.weight', 'blocks.13.norm2.bias', 'blocks.13.mlp.fc1.weight', 'blocks.13.mlp.fc1.bias', 'blocks.13.mlp.fc2.weight', 'blocks.13.mlp.fc2.bias', 'blocks.14.norm1.weight', 'blocks.14.norm1.bias', 'blocks.14.attn.qkv.weight', 'blocks.14.attn.qkv.bias', 'blocks.14.attn.proj.weight', 'blocks.14.attn.proj.bias', 'blocks.14.norm2.weight', 'blocks.14.norm2.bias', 'blocks.14.mlp.fc1.weight', 'blocks.14.mlp.fc1.bias', 'blocks.14.mlp.fc2.weight', 'blocks.14.mlp.fc2.bias', 'blocks.15.norm1.weight', 'blocks.15.norm1.bias', 'blocks.15.attn.qkv.weight', 'blocks.15.attn.qkv.bias', 'blocks.15.attn.proj.weight', 'blocks.15.attn.proj.bias', 'blocks.15.norm2.weight', 'blocks.15.norm2.bias', 'blocks.15.mlp.fc1.weight', 'blocks.15.mlp.fc1.bias', 'blocks.15.mlp.fc2.weight', 'blocks.15.mlp.fc2.bias', 'blocks.16.norm1.weight', 'blocks.16.norm1.bias', 'blocks.16.attn.qkv.weight', 'blocks.16.attn.qkv.bias', 'blocks.16.attn.proj.weight', 'blocks.16.attn.proj.bias', 'blocks.16.norm2.weight', 'blocks.16.norm2.bias', 'blocks.16.mlp.fc1.weight', 'blocks.16.mlp.fc1.bias', 'blocks.16.mlp.fc2.weight', 'blocks.16.mlp.fc2.bias', 'blocks.17.norm1.weight', 'blocks.17.norm1.bias', 'blocks.17.attn.qkv.weight', 'blocks.17.attn.qkv.bias', 'blocks.17.attn.proj.weight', 'blocks.17.attn.proj.bias', 'blocks.17.norm2.weight', 'blocks.17.norm2.bias', 'blocks.17.mlp.fc1.weight', 'blocks.17.mlp.fc1.bias', 'blocks.17.mlp.fc2.weight', 'blocks.17.mlp.fc2.bias', 'blocks.18.norm1.weight', 'blocks.18.norm1.bias', 'blocks.18.attn.qkv.weight', 'blocks.18.attn.qkv.bias', 'blocks.18.attn.proj.weight', 'blocks.18.attn.proj.bias', 'blocks.18.norm2.weight', 'blocks.18.norm2.bias', 'blocks.18.mlp.fc1.weight', 'blocks.18.mlp.fc1.bias', 'blocks.18.mlp.fc2.weight', 'blocks.18.mlp.fc2.bias', 'blocks.19.norm1.weight', 'blocks.19.norm1.bias', 'blocks.19.attn.qkv.weight', 'blocks.19.attn.qkv.bias', 'blocks.19.attn.proj.weight', 'blocks.19.attn.proj.bias', 'blocks.19.norm2.weight', 'blocks.19.norm2.bias', 'blocks.19.mlp.fc1.weight', 'blocks.19.mlp.fc1.bias', 'blocks.19.mlp.fc2.weight', 'blocks.19.mlp.fc2.bias', 'blocks.20.norm1.weight', 'blocks.20.norm1.bias', 'blocks.20.attn.qkv.weight', 'blocks.20.attn.qkv.bias', 'blocks.20.attn.proj.weight', 'blocks.20.attn.proj.bias', 'blocks.20.norm2.weight', 'blocks.20.norm2.bias', 'blocks.20.mlp.fc1.weight', 'blocks.20.mlp.fc1.bias', 'blocks.20.mlp.fc2.weight', 'blocks.20.mlp.fc2.bias', 'blocks.21.norm1.weight', 'blocks.21.norm1.bias', 'blocks.21.attn.qkv.weight', 'blocks.21.attn.qkv.bias', 'blocks.21.attn.proj.weight', 'blocks.21.attn.proj.bias', 'blocks.21.norm2.weight', 'blocks.21.norm2.bias', 'blocks.21.mlp.fc1.weight', 'blocks.21.mlp.fc1.bias', 'blocks.21.mlp.fc2.weight', 'blocks.21.mlp.fc2.bias', 'blocks.22.norm1.weight', 'blocks.22.norm1.bias', 'blocks.22.attn.qkv.weight', 'blocks.22.attn.qkv.bias', 'blocks.22.attn.proj.weight', 'blocks.22.attn.proj.bias', 'blocks.22.norm2.weight', 'blocks.22.norm2.bias', 'blocks.22.mlp.fc1.weight', 'blocks.22.mlp.fc1.bias', 'blocks.22.mlp.fc2.weight', 'blocks.22.mlp.fc2.bias', 'blocks.23.norm1.weight', 'blocks.23.norm1.bias', 'blocks.23.attn.qkv.weight', 'blocks.23.attn.qkv.bias', 'blocks.23.attn.proj.weight', 'blocks.23.attn.proj.bias', 'blocks.23.norm2.weight', 'blocks.23.norm2.bias', 'blocks.23.mlp.fc1.weight', 'blocks.23.mlp.fc1.bias', 'blocks.23.mlp.fc2.weight', 'blocks.23.mlp.fc2.bias', 'norm.weight', 'norm.bias'], unexpected_keys=['module.backbone.patch_embed.proj.weight', 'module.backbone.patch_embed.proj.bias', 'module.backbone.blocks.0.norm1.weight', 'module.backbone.blocks.0.norm1.bias', 'module.backbone.blocks.0.attn.qkv.weight', 'module.backbone.blocks.0.attn.qkv.bias', 'module.backbone.blocks.0.attn.proj.weight', 'module.backbone.blocks.0.attn.proj.bias', 'module.backbone.blocks.0.norm2.weight', 'module.backbone.blocks.0.norm2.bias', 'module.backbone.blocks.0.mlp.fc1.weight', 'module.backbone.blocks.0.mlp.fc1.bias', 'module.backbone.blocks.0.mlp.fc2.weight', 'module.backbone.blocks.0.mlp.fc2.bias', 'module.backbone.blocks.1.norm1.weight', 'module.backbone.blocks.1.norm1.bias', 'module.backbone.blocks.1.attn.qkv.weight', 'module.backbone.blocks.1.attn.qkv.bias', 'module.backbone.blocks.1.attn.proj.weight', 'module.backbone.blocks.1.attn.proj.bias', 'module.backbone.blocks.1.norm2.weight', 'module.backbone.blocks.1.norm2.bias', 'module.backbone.blocks.1.mlp.fc1.weight', 'module.backbone.blocks.1.mlp.fc1.bias', 'module.backbone.blocks.1.mlp.fc2.weight', 'module.backbone.blocks.1.mlp.fc2.bias', 'module.backbone.blocks.2.norm1.weight', 'module.backbone.blocks.2.norm1.bias', 'module.backbone.blocks.2.attn.qkv.weight', 'module.backbone.blocks.2.attn.qkv.bias', 'module.backbone.blocks.2.attn.proj.weight', 'module.backbone.blocks.2.attn.proj.bias', 'module.backbone.blocks.2.norm2.weight', 'module.backbone.blocks.2.norm2.bias', 'module.backbone.blocks.2.mlp.fc1.weight', 'module.backbone.blocks.2.mlp.fc1.bias', 'module.backbone.blocks.2.mlp.fc2.weight', 'module.backbone.blocks.2.mlp.fc2.bias', 'module.backbone.blocks.3.norm1.weight', 'module.backbone.blocks.3.norm1.bias', 'module.backbone.blocks.3.attn.qkv.weight', 'module.backbone.blocks.3.attn.qkv.bias', 'module.backbone.blocks.3.attn.proj.weight', 'module.backbone.blocks.3.attn.proj.bias', 'module.backbone.blocks.3.norm2.weight', 'module.backbone.blocks.3.norm2.bias', 'module.backbone.blocks.3.mlp.fc1.weight', 'module.backbone.blocks.3.mlp.fc1.bias', 'module.backbone.blocks.3.mlp.fc2.weight', 'module.backbone.blocks.3.mlp.fc2.bias', 'module.backbone.blocks.4.norm1.weight', 'module.backbone.blocks.4.norm1.bias', 'module.backbone.blocks.4.attn.qkv.weight', 'module.backbone.blocks.4.attn.qkv.bias', 'module.backbone.blocks.4.attn.proj.weight', 'module.backbone.blocks.4.attn.proj.bias', 'module.backbone.blocks.4.norm2.weight', 'module.backbone.blocks.4.norm2.bias', 'module.backbone.blocks.4.mlp.fc1.weight', 'module.backbone.blocks.4.mlp.fc1.bias', 'module.backbone.blocks.4.mlp.fc2.weight', 'module.backbone.blocks.4.mlp.fc2.bias', 'module.backbone.blocks.5.norm1.weight', 'module.backbone.blocks.5.norm1.bias', 'module.backbone.blocks.5.attn.qkv.weight', 'module.backbone.blocks.5.attn.qkv.bias', 'module.backbone.blocks.5.attn.proj.weight', 'module.backbone.blocks.5.attn.proj.bias', 'module.backbone.blocks.5.norm2.weight', 'module.backbone.blocks.5.norm2.bias', 'module.backbone.blocks.5.mlp.fc1.weight', 'module.backbone.blocks.5.mlp.fc1.bias', 'module.backbone.blocks.5.mlp.fc2.weight', 'module.backbone.blocks.5.mlp.fc2.bias', 'module.backbone.blocks.6.norm1.weight', 'module.backbone.blocks.6.norm1.bias', 'module.backbone.blocks.6.attn.qkv.weight', 'module.backbone.blocks.6.attn.qkv.bias', 'module.backbone.blocks.6.attn.proj.weight', 'module.backbone.blocks.6.attn.proj.bias', 'module.backbone.blocks.6.norm2.weight', 'module.backbone.blocks.6.norm2.bias', 'module.backbone.blocks.6.mlp.fc1.weight', 'module.backbone.blocks.6.mlp.fc1.bias', 'module.backbone.blocks.6.mlp.fc2.weight', 'module.backbone.blocks.6.mlp.fc2.bias', 'module.backbone.blocks.7.norm1.weight', 'module.backbone.blocks.7.norm1.bias', 'module.backbone.blocks.7.attn.qkv.weight', 'module.backbone.blocks.7.attn.qkv.bias', 'module.backbone.blocks.7.attn.proj.weight', 'module.backbone.blocks.7.attn.proj.bias', 'module.backbone.blocks.7.norm2.weight', 'module.backbone.blocks.7.norm2.bias', 'module.backbone.blocks.7.mlp.fc1.weight', 'module.backbone.blocks.7.mlp.fc1.bias', 'module.backbone.blocks.7.mlp.fc2.weight', 'module.backbone.blocks.7.mlp.fc2.bias', 'module.backbone.blocks.8.norm1.weight', 'module.backbone.blocks.8.norm1.bias', 'module.backbone.blocks.8.attn.qkv.weight', 'module.backbone.blocks.8.attn.qkv.bias', 'module.backbone.blocks.8.attn.proj.weight', 'module.backbone.blocks.8.attn.proj.bias', 'module.backbone.blocks.8.norm2.weight', 'module.backbone.blocks.8.norm2.bias', 'module.backbone.blocks.8.mlp.fc1.weight', 'module.backbone.blocks.8.mlp.fc1.bias', 'module.backbone.blocks.8.mlp.fc2.weight', 'module.backbone.blocks.8.mlp.fc2.bias', 'module.backbone.blocks.9.norm1.weight', 'module.backbone.blocks.9.norm1.bias', 'module.backbone.blocks.9.attn.qkv.weight', 'module.backbone.blocks.9.attn.qkv.bias', 'module.backbone.blocks.9.attn.proj.weight', 'module.backbone.blocks.9.attn.proj.bias', 'module.backbone.blocks.9.norm2.weight', 'module.backbone.blocks.9.norm2.bias', 'module.backbone.blocks.9.mlp.fc1.weight', 'module.backbone.blocks.9.mlp.fc1.bias', 'module.backbone.blocks.9.mlp.fc2.weight', 'module.backbone.blocks.9.mlp.fc2.bias', 'module.backbone.blocks.10.norm1.weight', 'module.backbone.blocks.10.norm1.bias', 'module.backbone.blocks.10.attn.qkv.weight', 'module.backbone.blocks.10.attn.qkv.bias', 'module.backbone.blocks.10.attn.proj.weight', 'module.backbone.blocks.10.attn.proj.bias', 'module.backbone.blocks.10.norm2.weight', 'module.backbone.blocks.10.norm2.bias', 'module.backbone.blocks.10.mlp.fc1.weight', 'module.backbone.blocks.10.mlp.fc1.bias', 'module.backbone.blocks.10.mlp.fc2.weight', 'module.backbone.blocks.10.mlp.fc2.bias', 'module.backbone.blocks.11.norm1.weight', 'module.backbone.blocks.11.norm1.bias', 'module.backbone.blocks.11.attn.qkv.weight', 'module.backbone.blocks.11.attn.qkv.bias', 'module.backbone.blocks.11.attn.proj.weight', 'module.backbone.blocks.11.attn.proj.bias', 'module.backbone.blocks.11.norm2.weight', 'module.backbone.blocks.11.norm2.bias', 'module.backbone.blocks.11.mlp.fc1.weight', 'module.backbone.blocks.11.mlp.fc1.bias', 'module.backbone.blocks.11.mlp.fc2.weight', 'module.backbone.blocks.11.mlp.fc2.bias', 'module.backbone.blocks.12.norm1.weight', 'module.backbone.blocks.12.norm1.bias', 'module.backbone.blocks.12.attn.qkv.weight', 'module.backbone.blocks.12.attn.qkv.bias', 'module.backbone.blocks.12.attn.proj.weight', 'module.backbone.blocks.12.attn.proj.bias', 'module.backbone.blocks.12.norm2.weight', 'module.backbone.blocks.12.norm2.bias', 'module.backbone.blocks.12.mlp.fc1.weight', 'module.backbone.blocks.12.mlp.fc1.bias', 'module.backbone.blocks.12.mlp.fc2.weight', 'module.backbone.blocks.12.mlp.fc2.bias', 'module.backbone.blocks.13.norm1.weight', 'module.backbone.blocks.13.norm1.bias', 'module.backbone.blocks.13.attn.qkv.weight', 'module.backbone.blocks.13.attn.qkv.bias', 'module.backbone.blocks.13.attn.proj.weight', 'module.backbone.blocks.13.attn.proj.bias', 'module.backbone.blocks.13.norm2.weight', 'module.backbone.blocks.13.norm2.bias', 'module.backbone.blocks.13.mlp.fc1.weight', 'module.backbone.blocks.13.mlp.fc1.bias', 'module.backbone.blocks.13.mlp.fc2.weight', 'module.backbone.blocks.13.mlp.fc2.bias', 'module.backbone.blocks.14.norm1.weight', 'module.backbone.blocks.14.norm1.bias', 'module.backbone.blocks.14.attn.qkv.weight', 'module.backbone.blocks.14.attn.qkv.bias', 'module.backbone.blocks.14.attn.proj.weight', 'module.backbone.blocks.14.attn.proj.bias', 'module.backbone.blocks.14.norm2.weight', 'module.backbone.blocks.14.norm2.bias', 'module.backbone.blocks.14.mlp.fc1.weight', 'module.backbone.blocks.14.mlp.fc1.bias', 'module.backbone.blocks.14.mlp.fc2.weight', 'module.backbone.blocks.14.mlp.fc2.bias', 'module.backbone.blocks.15.norm1.weight', 'module.backbone.blocks.15.norm1.bias', 'module.backbone.blocks.15.attn.qkv.weight', 'module.backbone.blocks.15.attn.qkv.bias', 'module.backbone.blocks.15.attn.proj.weight', 'module.backbone.blocks.15.attn.proj.bias', 'module.backbone.blocks.15.norm2.weight', 'module.backbone.blocks.15.norm2.bias', 'module.backbone.blocks.15.mlp.fc1.weight', 'module.backbone.blocks.15.mlp.fc1.bias', 'module.backbone.blocks.15.mlp.fc2.weight', 'module.backbone.blocks.15.mlp.fc2.bias', 'module.backbone.blocks.16.norm1.weight', 'module.backbone.blocks.16.norm1.bias', 'module.backbone.blocks.16.attn.qkv.weight', 'module.backbone.blocks.16.attn.qkv.bias', 'module.backbone.blocks.16.attn.proj.weight', 'module.backbone.blocks.16.attn.proj.bias', 'module.backbone.blocks.16.norm2.weight', 'module.backbone.blocks.16.norm2.bias', 'module.backbone.blocks.16.mlp.fc1.weight', 'module.backbone.blocks.16.mlp.fc1.bias', 'module.backbone.blocks.16.mlp.fc2.weight', 'module.backbone.blocks.16.mlp.fc2.bias', 'module.backbone.blocks.17.norm1.weight', 'module.backbone.blocks.17.norm1.bias', 'module.backbone.blocks.17.attn.qkv.weight', 'module.backbone.blocks.17.attn.qkv.bias', 'module.backbone.blocks.17.attn.proj.weight', 'module.backbone.blocks.17.attn.proj.bias', 'module.backbone.blocks.17.norm2.weight', 'module.backbone.blocks.17.norm2.bias', 'module.backbone.blocks.17.mlp.fc1.weight', 'module.backbone.blocks.17.mlp.fc1.bias', 'module.backbone.blocks.17.mlp.fc2.weight', 'module.backbone.blocks.17.mlp.fc2.bias', 'module.backbone.blocks.18.norm1.weight', 'module.backbone.blocks.18.norm1.bias', 'module.backbone.blocks.18.attn.qkv.weight', 'module.backbone.blocks.18.attn.qkv.bias', 'module.backbone.blocks.18.attn.proj.weight', 'module.backbone.blocks.18.attn.proj.bias', 'module.backbone.blocks.18.norm2.weight', 'module.backbone.blocks.18.norm2.bias', 'module.backbone.blocks.18.mlp.fc1.weight', 'module.backbone.blocks.18.mlp.fc1.bias', 'module.backbone.blocks.18.mlp.fc2.weight', 'module.backbone.blocks.18.mlp.fc2.bias', 'module.backbone.blocks.19.norm1.weight', 'module.backbone.blocks.19.norm1.bias', 'module.backbone.blocks.19.attn.qkv.weight', 'module.backbone.blocks.19.attn.qkv.bias', 'module.backbone.blocks.19.attn.proj.weight', 'module.backbone.blocks.19.attn.proj.bias', 'module.backbone.blocks.19.norm2.weight', 'module.backbone.blocks.19.norm2.bias', 'module.backbone.blocks.19.mlp.fc1.weight', 'module.backbone.blocks.19.mlp.fc1.bias', 'module.backbone.blocks.19.mlp.fc2.weight', 'module.backbone.blocks.19.mlp.fc2.bias', 'module.backbone.blocks.20.norm1.weight', 'module.backbone.blocks.20.norm1.bias', 'module.backbone.blocks.20.attn.qkv.weight', 'module.backbone.blocks.20.attn.qkv.bias', 'module.backbone.blocks.20.attn.proj.weight', 'module.backbone.blocks.20.attn.proj.bias', 'module.backbone.blocks.20.norm2.weight', 'module.backbone.blocks.20.norm2.bias', 'module.backbone.blocks.20.mlp.fc1.weight', 'module.backbone.blocks.20.mlp.fc1.bias', 'module.backbone.blocks.20.mlp.fc2.weight', 'module.backbone.blocks.20.mlp.fc2.bias', 'module.backbone.blocks.21.norm1.weight', 'module.backbone.blocks.21.norm1.bias', 'module.backbone.blocks.21.attn.qkv.weight', 'module.backbone.blocks.21.attn.qkv.bias', 'module.backbone.blocks.21.attn.proj.weight', 'module.backbone.blocks.21.attn.proj.bias', 'module.backbone.blocks.21.norm2.weight', 'module.backbone.blocks.21.norm2.bias', 'module.backbone.blocks.21.mlp.fc1.weight', 'module.backbone.blocks.21.mlp.fc1.bias', 'module.backbone.blocks.21.mlp.fc2.weight', 'module.backbone.blocks.21.mlp.fc2.bias', 'module.backbone.blocks.22.norm1.weight', 'module.backbone.blocks.22.norm1.bias', 'module.backbone.blocks.22.attn.qkv.weight', 'module.backbone.blocks.22.attn.qkv.bias', 'module.backbone.blocks.22.attn.proj.weight', 'module.backbone.blocks.22.attn.proj.bias', 'module.backbone.blocks.22.norm2.weight', 'module.backbone.blocks.22.norm2.bias', 'module.backbone.blocks.22.mlp.fc1.weight', 'module.backbone.blocks.22.mlp.fc1.bias', 'module.backbone.blocks.22.mlp.fc2.weight', 'module.backbone.blocks.22.mlp.fc2.bias', 'module.backbone.blocks.23.norm1.weight', 'module.backbone.blocks.23.norm1.bias', 'module.backbone.blocks.23.attn.qkv.weight', 'module.backbone.blocks.23.attn.qkv.bias', 'module.backbone.blocks.23.attn.proj.weight', 'module.backbone.blocks.23.attn.proj.bias', 'module.backbone.blocks.23.norm2.weight', 'module.backbone.blocks.23.norm2.bias', 'module.backbone.blocks.23.mlp.fc1.weight', 'module.backbone.blocks.23.mlp.fc1.bias', 'module.backbone.blocks.23.mlp.fc2.weight', 'module.backbone.blocks.23.mlp.fc2.bias', 'module.backbone.norm.weight', 'module.backbone.norm.bias'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(pretrained_dict, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bd4f9",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b24fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### # Example 100 episodes from the DROID dataset in RLDS for debugging (2GB)\n",
    "#### !gsutil -m cp -r gs://gresearch/robotics/droid_100 mydroiddata/droid-256px-8f/dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading Gupta Lab data from the full dataset\n",
    "# !sh copy-droid-data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following this issue: https://github.com/facebookresearch/vjepa2/issues/65\n",
    "import os\n",
    "\n",
    "def prepare_droid_index_file(start_folder_path, output_csv_path):\n",
    "    # Which folders conttains the .h5 files\n",
    "    cwd = os.getcwd()\n",
    "    parent_folder_full_paths = []\n",
    "    for root, dirs, files in os.walk(start_folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".h5\"):\n",
    "                parent_folder_full_paths.append(os.path.join(cwd, root))\n",
    "                break\n",
    "    parent_folder_full_paths = sorted(list(set(parent_folder_full_paths)))\n",
    "    # Write to csv\n",
    "    with open(output_csv_path, \"w\") as f:\n",
    "        for folder_path in parent_folder_full_paths:\n",
    "            f.write(f\"{folder_path}\\n\")\n",
    "    print(f\"Written droid index file to {output_csv_path}, with {len(parent_folder_full_paths)} episode paths.\")\n",
    "\n",
    "\n",
    "\n",
    "# prepare_droid_index_file(\n",
    "#     start_folder_path=\"mydroiddata/dataset/droid_raw/\",\n",
    "#     output_csv_path=\"mydroiddata/dataset/droid_raw/droid_index.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94762fb4",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.vjepa_droid.transforms import make_transforms\n",
    "from app.vjepa_droid.droid import init_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_collator = torch.utils.data.default_collate\n",
    "transform = make_transforms(\n",
    "    random_horizontal_flip=horizontal_flip,\n",
    "    random_resize_aspect_ratio=ar_range,\n",
    "    random_resize_scale=rr_scale,\n",
    "    reprob=reprob,\n",
    "    auto_augment=use_aa,\n",
    "    motion_shift=motion_shift,\n",
    "    crop_size=crop_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- init data-loaders/samplers\n",
    "(unsupervised_loader, unsupervised_sampler) = init_data(\n",
    "    data_path=dataset_path,\n",
    "    batch_size=batch_size,\n",
    "    frames_per_clip=max_num_frames,\n",
    "    tubelet_size=1,\n",
    "    fps=fps,\n",
    "    camera_views=camera_views,\n",
    "    camera_frame=camera_frame,\n",
    "    stereo_view=stereo_view,\n",
    "    transform=transform,\n",
    "    collator=video_collator,\n",
    "    num_workers=num_workers,\n",
    "    world_size=world_size,\n",
    "    pin_mem=pin_mem,\n",
    "    persistent_workers=persistent_workers,\n",
    "    rank=rank,\n",
    ")\n",
    "\n",
    "_dlen = len(unsupervised_loader)\n",
    "if ipe is None:\n",
    "    ipe = _dlen\n",
    "logger.info(f\"iterations per epoch/dataset length: {ipe}/{_dlen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07661d3b",
   "metadata": {},
   "source": [
    "## Optimizer and LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- init optimizer and scheduler\n",
    "optimizer, scaler, scheduler, wd_scheduler = init_opt(\n",
    "    encoder=encoder,\n",
    "    predictor=predictor,\n",
    "    wd=wd,\n",
    "    final_wd=final_wd,\n",
    "    start_lr=start_lr,\n",
    "    ref_lr=lr,\n",
    "    final_lr=final_lr,\n",
    "    enc_lr_scale=enc_lr_scale,\n",
    "    iterations_per_epoch=ipe,\n",
    "    anneal=anneal,\n",
    "    warmup=warmup,\n",
    "    num_epochs=num_epochs,\n",
    "    mixed_precision=mixed_precision,\n",
    "    betas=betas,\n",
    "    eps=eps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628076e",
   "metadata": {},
   "source": [
    "## Warming up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea548ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "# -- load training checkpoint\n",
    "if os.path.exists(latest_path):\n",
    "    (\n",
    "        encoder,\n",
    "        predictor,\n",
    "        target_encoder,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        start_epoch,\n",
    "    ) = load_checkpoint(\n",
    "        r_path=resume_path,\n",
    "        encoder=encoder,\n",
    "        predictor=predictor,\n",
    "        target_encoder=target_encoder,\n",
    "        opt=optimizer,\n",
    "        scaler=scaler,\n",
    "    )\n",
    "    for _ in range(start_epoch * ipe):\n",
    "        scheduler.step()\n",
    "        wd_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1854fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, path):\n",
    "    if rank != 0:\n",
    "        return\n",
    "    save_dict = {\n",
    "        \"encoder\": encoder.state_dict(),\n",
    "        \"predictor\": predictor.state_dict(),\n",
    "        \"opt\": optimizer.state_dict(),\n",
    "        \"scaler\": None if scaler is None else scaler.state_dict(),\n",
    "        \"target_encoder\": target_encoder.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"loss\": loss_meter.avg,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"world_size\": world_size,\n",
    "        \"lr\": lr,\n",
    "    }\n",
    "    try:\n",
    "        torch.save(save_dict, path)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Encountered exception when saving checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec436b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing loader...\")\n",
    "unsupervised_sampler.set_epoch(start_epoch)\n",
    "loader = iter(unsupervised_loader)\n",
    "\n",
    "if skip_batches > 0:\n",
    "    logger.info(f\"Skip {skip_batches} batches\")\n",
    "    # -- update distributed-data-loader epoch\n",
    "\n",
    "    for itr in range(skip_batches):\n",
    "        if itr % 10 == 0:\n",
    "            logger.info(f\"Skip {itr}/{skip_batches} batches\")\n",
    "        try:\n",
    "            _ = next(loader)\n",
    "        except Exception:\n",
    "            loader = iter(unsupervised_loader)\n",
    "            _ = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdbb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sync_gc:\n",
    "    gc.disable()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cff663",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328c9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sample:\n",
    "    print(key.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73355a13",
   "metadata": {},
   "source": [
    "## Plot the videousing subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f08794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "video = sample[0][0]\n",
    "# Permute to (1,2,3,0)\n",
    "video = video.permute(1,2,3,0).cpu().numpy() # Shape (T,H,W,C)\n",
    "for t in range(video.shape[0]):\n",
    "    plt.subplot(4, 4, t+1)\n",
    "    plt.imshow(video[t])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e3389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520c334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vjepa2-low-config",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
